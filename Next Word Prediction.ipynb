{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98fc5491",
   "metadata": {},
   "source": [
    "# üè∑Ô∏èüè∑Ô∏è Next Word Prediction üè∑Ô∏èüè∑Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777fac0e",
   "metadata": {},
   "source": [
    "#### <center><img src= 'https://media2.giphy.com/media/v1.Y2lkPTc5MGI3NjExbXhiOW01eXltNnF1emxzZW53ZGhyODE2Znd5amhscGk0dnVzNWl4byZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/bGgsc5mWoryfgKBx1u/giphy.gif' width=\"300\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf38a52",
   "metadata": {},
   "source": [
    "### Making the Pairs of words to find in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8756dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4ebd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\user\\Downloads\\big.txt\",'r') as fd:\n",
    "    lines = fd.readlines()\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        words += re.findall('\\w+', line.lower())\n",
    "        \n",
    "def get_pairs(words):\n",
    "    data = []\n",
    "    for i in range(len(words)-1):\n",
    "        data.append(' '.join(words[i:i+2]))\n",
    "    return data\n",
    "\n",
    "data = get_pairs(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaa42b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the project',\n",
       " 'project gutenberg',\n",
       " 'gutenberg ebook',\n",
       " 'ebook of',\n",
       " 'of the',\n",
       " 'the adventures',\n",
       " 'adventures of',\n",
       " 'of sherlock',\n",
       " 'sherlock holmes',\n",
       " 'holmes by',\n",
       " 'by sir',\n",
       " 'sir arthur',\n",
       " 'arthur conan',\n",
       " 'conan doyle',\n",
       " 'doyle 15',\n",
       " '15 in',\n",
       " 'in our',\n",
       " 'our series',\n",
       " 'series by',\n",
       " 'by sir',\n",
       " 'sir arthur',\n",
       " 'arthur conan',\n",
       " 'conan doyle',\n",
       " 'doyle copyright',\n",
       " 'copyright laws',\n",
       " 'laws are',\n",
       " 'are changing',\n",
       " 'changing all',\n",
       " 'all over',\n",
       " 'over the',\n",
       " 'the world',\n",
       " 'world be',\n",
       " 'be sure',\n",
       " 'sure to',\n",
       " 'to check',\n",
       " 'check the',\n",
       " 'the copyright',\n",
       " 'copyright laws',\n",
       " 'laws for',\n",
       " 'for your',\n",
       " 'your country',\n",
       " 'country before',\n",
       " 'before downloading',\n",
       " 'downloading or',\n",
       " 'or redistributing',\n",
       " 'redistributing this',\n",
       " 'this or',\n",
       " 'or any',\n",
       " 'any other',\n",
       " 'other project',\n",
       " 'project gutenberg',\n",
       " 'gutenberg ebook',\n",
       " 'ebook this',\n",
       " 'this header',\n",
       " 'header should',\n",
       " 'should be',\n",
       " 'be the',\n",
       " 'the first',\n",
       " 'first thing',\n",
       " 'thing seen',\n",
       " 'seen when',\n",
       " 'when viewing',\n",
       " 'viewing this',\n",
       " 'this project',\n",
       " 'project gutenberg',\n",
       " 'gutenberg file',\n",
       " 'file please',\n",
       " 'please do',\n",
       " 'do not',\n",
       " 'not remove',\n",
       " 'remove it',\n",
       " 'it do',\n",
       " 'do not',\n",
       " 'not change',\n",
       " 'change or',\n",
       " 'or edit',\n",
       " 'edit the',\n",
       " 'the header',\n",
       " 'header without',\n",
       " 'without written',\n",
       " 'written permission',\n",
       " 'permission please',\n",
       " 'please read',\n",
       " 'read the',\n",
       " 'the legal',\n",
       " 'legal small',\n",
       " 'small print',\n",
       " 'print and',\n",
       " 'and other',\n",
       " 'other information',\n",
       " 'information about',\n",
       " 'about the',\n",
       " 'the ebook',\n",
       " 'ebook and',\n",
       " 'and project',\n",
       " 'project gutenberg',\n",
       " 'gutenberg at',\n",
       " 'at the',\n",
       " 'the bottom',\n",
       " 'bottom of',\n",
       " 'of this',\n",
       " 'this file',\n",
       " 'file included',\n",
       " 'included is',\n",
       " 'is important',\n",
       " 'important information',\n",
       " 'information about',\n",
       " 'about your',\n",
       " 'your specific',\n",
       " 'specific rights',\n",
       " 'rights and',\n",
       " 'and restrictions',\n",
       " 'restrictions in',\n",
       " 'in how',\n",
       " 'how the',\n",
       " 'the file',\n",
       " 'file may',\n",
       " 'may be',\n",
       " 'be used',\n",
       " 'used you',\n",
       " 'you can',\n",
       " 'can also',\n",
       " 'also find',\n",
       " 'find out',\n",
       " 'out about',\n",
       " 'about how',\n",
       " 'how to',\n",
       " 'to make',\n",
       " 'make a',\n",
       " 'a donation',\n",
       " 'donation to',\n",
       " 'to project',\n",
       " 'project gutenberg',\n",
       " 'gutenberg and',\n",
       " 'and how',\n",
       " 'how to',\n",
       " 'to get',\n",
       " 'get involved',\n",
       " 'involved welcome',\n",
       " 'welcome to',\n",
       " 'to the',\n",
       " 'the world',\n",
       " 'world of',\n",
       " 'of free',\n",
       " 'free plain',\n",
       " 'plain vanilla',\n",
       " 'vanilla electronic',\n",
       " 'electronic texts',\n",
       " 'texts ebooks',\n",
       " 'ebooks readable',\n",
       " 'readable by',\n",
       " 'by both',\n",
       " 'both humans',\n",
       " 'humans and',\n",
       " 'and by',\n",
       " 'by computers',\n",
       " 'computers since',\n",
       " 'since 1971',\n",
       " '1971 these',\n",
       " 'these ebooks',\n",
       " 'ebooks were',\n",
       " 'were prepared',\n",
       " 'prepared by',\n",
       " 'by thousands',\n",
       " 'thousands of',\n",
       " 'of volunteers',\n",
       " 'volunteers title',\n",
       " 'title the',\n",
       " 'the adventures',\n",
       " 'adventures of',\n",
       " 'of sherlock',\n",
       " 'sherlock holmes',\n",
       " 'holmes author',\n",
       " 'author sir',\n",
       " 'sir arthur',\n",
       " 'arthur conan',\n",
       " 'conan doyle',\n",
       " 'doyle release',\n",
       " 'release date',\n",
       " 'date march',\n",
       " 'march 1999',\n",
       " '1999 ebook',\n",
       " 'ebook 1661',\n",
       " '1661 most',\n",
       " 'most recently',\n",
       " 'recently updated',\n",
       " 'updated november',\n",
       " 'november 29',\n",
       " '29 2002',\n",
       " '2002 edition',\n",
       " 'edition 12',\n",
       " '12 language',\n",
       " 'language english',\n",
       " 'english character',\n",
       " 'character set',\n",
       " 'set encoding',\n",
       " 'encoding ascii',\n",
       " 'ascii start',\n",
       " 'start of',\n",
       " 'of the',\n",
       " 'the project',\n",
       " 'project gutenberg',\n",
       " 'gutenberg ebook',\n",
       " 'ebook the',\n",
       " 'the adventures',\n",
       " 'adventures of',\n",
       " 'of sherlock',\n",
       " 'sherlock holmes',\n",
       " 'holmes additional',\n",
       " 'additional editing',\n",
       " 'editing by',\n",
       " 'by jose',\n",
       " 'jose menendez',\n",
       " 'menendez the',\n",
       " 'the adventures',\n",
       " 'adventures of',\n",
       " 'of sherlock',\n",
       " 'sherlock holmes',\n",
       " 'holmes by',\n",
       " 'by sir',\n",
       " 'sir arthur',\n",
       " 'arthur conan',\n",
       " 'conan doyle',\n",
       " 'doyle contents',\n",
       " 'contents i',\n",
       " 'i a',\n",
       " 'a scandal',\n",
       " 'scandal in',\n",
       " 'in bohemia',\n",
       " 'bohemia ii',\n",
       " 'ii the',\n",
       " 'the red',\n",
       " 'red headed',\n",
       " 'headed league',\n",
       " 'league iii',\n",
       " 'iii a',\n",
       " 'a case',\n",
       " 'case of',\n",
       " 'of identity',\n",
       " 'identity iv',\n",
       " 'iv the',\n",
       " 'the boscombe',\n",
       " 'boscombe valley',\n",
       " 'valley mystery',\n",
       " 'mystery v',\n",
       " 'v the',\n",
       " 'the five',\n",
       " 'five orange',\n",
       " 'orange pips',\n",
       " 'pips vi',\n",
       " 'vi the',\n",
       " 'the man',\n",
       " 'man with',\n",
       " 'with the',\n",
       " 'the twisted',\n",
       " 'twisted lip',\n",
       " 'lip vii',\n",
       " 'vii the',\n",
       " 'the adventure',\n",
       " 'adventure of',\n",
       " 'of the',\n",
       " 'the blue',\n",
       " 'blue carbuncle',\n",
       " 'carbuncle viii',\n",
       " 'viii the',\n",
       " 'the adventure',\n",
       " 'adventure of',\n",
       " 'of the',\n",
       " 'the speckled',\n",
       " 'speckled band',\n",
       " 'band ix',\n",
       " 'ix the',\n",
       " 'the adventure',\n",
       " 'adventure of',\n",
       " 'of the',\n",
       " 'the engineer',\n",
       " 'engineer s',\n",
       " 's thumb',\n",
       " 'thumb x',\n",
       " 'x the',\n",
       " 'the adventure',\n",
       " 'adventure of',\n",
       " 'of the',\n",
       " 'the noble',\n",
       " 'noble bachelor',\n",
       " 'bachelor xi',\n",
       " 'xi the',\n",
       " 'the adventure',\n",
       " 'adventure of',\n",
       " 'of the',\n",
       " 'the beryl',\n",
       " 'beryl coronet',\n",
       " 'coronet xii',\n",
       " 'xii the',\n",
       " 'the adventure',\n",
       " 'adventure of',\n",
       " 'of the',\n",
       " 'the copper',\n",
       " 'copper beeches',\n",
       " 'beeches adventure',\n",
       " 'adventure i',\n",
       " 'i a',\n",
       " 'a scandal',\n",
       " 'scandal in',\n",
       " 'in bohemia',\n",
       " 'bohemia i',\n",
       " 'i to',\n",
       " 'to sherlock',\n",
       " 'sherlock holmes',\n",
       " 'holmes she',\n",
       " 'she is',\n",
       " 'is always',\n",
       " 'always the',\n",
       " 'the woman',\n",
       " 'woman i',\n",
       " 'i have',\n",
       " 'have seldom',\n",
       " 'seldom heard',\n",
       " 'heard him',\n",
       " 'him mention',\n",
       " 'mention her',\n",
       " 'her under',\n",
       " 'under any',\n",
       " 'any other',\n",
       " 'other name',\n",
       " 'name in',\n",
       " 'in his',\n",
       " 'his eyes',\n",
       " 'eyes she',\n",
       " 'she eclipses',\n",
       " 'eclipses and',\n",
       " 'and predominates',\n",
       " 'predominates the',\n",
       " 'the whole',\n",
       " 'whole of',\n",
       " 'of her',\n",
       " 'her sex',\n",
       " 'sex it',\n",
       " 'it was',\n",
       " 'was not',\n",
       " 'not that',\n",
       " 'that he',\n",
       " 'he felt',\n",
       " 'felt any',\n",
       " 'any emotion',\n",
       " 'emotion akin',\n",
       " 'akin to',\n",
       " 'to love',\n",
       " 'love for',\n",
       " 'for irene',\n",
       " 'irene adler',\n",
       " 'adler all',\n",
       " 'all emotions',\n",
       " 'emotions and',\n",
       " 'and that',\n",
       " 'that one',\n",
       " 'one particularly',\n",
       " 'particularly were',\n",
       " 'were abhorrent',\n",
       " 'abhorrent to',\n",
       " 'to his',\n",
       " 'his cold',\n",
       " 'cold precise',\n",
       " 'precise but',\n",
       " 'but admirably',\n",
       " 'admirably balanced',\n",
       " 'balanced mind',\n",
       " 'mind he',\n",
       " 'he was',\n",
       " 'was i',\n",
       " 'i take',\n",
       " 'take it',\n",
       " 'it the',\n",
       " 'the most',\n",
       " 'most perfect',\n",
       " 'perfect reasoning',\n",
       " 'reasoning and',\n",
       " 'and observing',\n",
       " 'observing machine',\n",
       " 'machine that',\n",
       " 'that the',\n",
       " 'the world',\n",
       " 'world has',\n",
       " 'has seen',\n",
       " 'seen but',\n",
       " 'but as',\n",
       " 'as a',\n",
       " 'a lover',\n",
       " 'lover he',\n",
       " 'he would',\n",
       " 'would have',\n",
       " 'have placed',\n",
       " 'placed himself',\n",
       " 'himself in',\n",
       " 'in a',\n",
       " 'a false',\n",
       " 'false position',\n",
       " 'position he',\n",
       " 'he never',\n",
       " 'never spoke',\n",
       " 'spoke of',\n",
       " 'of the',\n",
       " 'the softer',\n",
       " 'softer passions',\n",
       " 'passions save',\n",
       " 'save with',\n",
       " 'with a',\n",
       " 'a gibe',\n",
       " 'gibe and',\n",
       " 'and a',\n",
       " 'a sneer',\n",
       " 'sneer they',\n",
       " 'they were',\n",
       " 'were admirable',\n",
       " 'admirable things',\n",
       " 'things for',\n",
       " 'for the',\n",
       " 'the observer',\n",
       " 'observer excellent',\n",
       " 'excellent for',\n",
       " 'for drawing',\n",
       " 'drawing the',\n",
       " 'the veil',\n",
       " 'veil from',\n",
       " 'from men',\n",
       " 'men s',\n",
       " 's motives',\n",
       " 'motives and',\n",
       " 'and actions',\n",
       " 'actions but',\n",
       " 'but for',\n",
       " 'for the',\n",
       " 'the trained',\n",
       " 'trained reasoner',\n",
       " 'reasoner to',\n",
       " 'to admit',\n",
       " 'admit such',\n",
       " 'such intrusions',\n",
       " 'intrusions into',\n",
       " 'into his',\n",
       " 'his own',\n",
       " 'own delicate',\n",
       " 'delicate and',\n",
       " 'and finely',\n",
       " 'finely adjusted',\n",
       " 'adjusted temperament',\n",
       " 'temperament was',\n",
       " 'was to',\n",
       " 'to introduce',\n",
       " 'introduce a',\n",
       " 'a distracting',\n",
       " 'distracting factor',\n",
       " 'factor which',\n",
       " 'which might',\n",
       " 'might throw',\n",
       " 'throw a',\n",
       " 'a doubt',\n",
       " 'doubt upon',\n",
       " 'upon all',\n",
       " 'all his',\n",
       " 'his mental',\n",
       " 'mental results',\n",
       " 'results grit',\n",
       " 'grit in',\n",
       " 'in a',\n",
       " 'a sensitive',\n",
       " 'sensitive instrument',\n",
       " 'instrument or',\n",
       " 'or a',\n",
       " 'a crack',\n",
       " 'crack in',\n",
       " 'in one',\n",
       " 'one of',\n",
       " 'of his',\n",
       " 'his own',\n",
       " 'own high',\n",
       " 'high power',\n",
       " 'power lenses',\n",
       " 'lenses would',\n",
       " 'would not',\n",
       " 'not be',\n",
       " 'be more',\n",
       " 'more disturbing',\n",
       " 'disturbing than',\n",
       " 'than a',\n",
       " 'a strong',\n",
       " 'strong emotion',\n",
       " 'emotion in',\n",
       " 'in a',\n",
       " 'a nature',\n",
       " 'nature such',\n",
       " 'such as',\n",
       " 'as his',\n",
       " 'his and',\n",
       " 'and yet',\n",
       " 'yet there',\n",
       " 'there was',\n",
       " 'was but',\n",
       " 'but one',\n",
       " 'one woman',\n",
       " 'woman to',\n",
       " 'to him',\n",
       " 'him and',\n",
       " 'and that',\n",
       " 'that woman',\n",
       " 'woman was',\n",
       " 'was the',\n",
       " 'the late',\n",
       " 'late irene',\n",
       " 'irene adler',\n",
       " 'adler of',\n",
       " 'of dubious',\n",
       " 'dubious and',\n",
       " 'and questionable',\n",
       " 'questionable memory',\n",
       " 'memory i',\n",
       " 'i had',\n",
       " 'had seen',\n",
       " 'seen little',\n",
       " 'little of',\n",
       " 'of holmes',\n",
       " 'holmes lately',\n",
       " 'lately my',\n",
       " 'my marriage',\n",
       " 'marriage had',\n",
       " 'had drifted',\n",
       " 'drifted us',\n",
       " 'us away',\n",
       " 'away from',\n",
       " 'from each',\n",
       " 'each other',\n",
       " 'other my',\n",
       " 'my own',\n",
       " 'own complete',\n",
       " 'complete happiness',\n",
       " 'happiness and',\n",
       " 'and the',\n",
       " 'the home',\n",
       " 'home centred',\n",
       " 'centred interests',\n",
       " 'interests which',\n",
       " 'which rise',\n",
       " 'rise up',\n",
       " 'up around',\n",
       " 'around the',\n",
       " 'the man',\n",
       " 'man who',\n",
       " 'who first',\n",
       " 'first finds',\n",
       " 'finds himself',\n",
       " 'himself master',\n",
       " 'master of',\n",
       " 'of his',\n",
       " 'his own',\n",
       " 'own establishment',\n",
       " 'establishment were',\n",
       " 'were sufficient',\n",
       " 'sufficient to',\n",
       " 'to absorb',\n",
       " 'absorb all',\n",
       " 'all my',\n",
       " 'my attention',\n",
       " 'attention while',\n",
       " 'while holmes',\n",
       " 'holmes who',\n",
       " 'who loathed',\n",
       " 'loathed every',\n",
       " 'every form',\n",
       " 'form of',\n",
       " 'of society',\n",
       " 'society with',\n",
       " 'with his',\n",
       " 'his whole',\n",
       " 'whole bohemian',\n",
       " 'bohemian soul',\n",
       " 'soul remained',\n",
       " 'remained in',\n",
       " 'in our',\n",
       " 'our lodgings',\n",
       " 'lodgings in',\n",
       " 'in baker',\n",
       " 'baker street',\n",
       " 'street buried',\n",
       " 'buried among',\n",
       " 'among his',\n",
       " 'his old',\n",
       " 'old books',\n",
       " 'books and',\n",
       " 'and alternating',\n",
       " 'alternating from',\n",
       " 'from week',\n",
       " 'week to',\n",
       " 'to week',\n",
       " 'week between',\n",
       " 'between cocaine',\n",
       " 'cocaine and',\n",
       " 'and ambition',\n",
       " 'ambition the',\n",
       " 'the drowsiness',\n",
       " 'drowsiness of',\n",
       " 'of the',\n",
       " 'the drug',\n",
       " 'drug and',\n",
       " 'and the',\n",
       " 'the fierce',\n",
       " 'fierce energy',\n",
       " 'energy of',\n",
       " 'of his',\n",
       " 'his own',\n",
       " 'own keen',\n",
       " 'keen nature',\n",
       " 'nature he',\n",
       " 'he was',\n",
       " 'was still',\n",
       " 'still as',\n",
       " 'as ever',\n",
       " 'ever deeply',\n",
       " 'deeply attracted',\n",
       " 'attracted by',\n",
       " 'by the',\n",
       " 'the study',\n",
       " 'study of',\n",
       " 'of crime',\n",
       " 'crime and',\n",
       " 'and occupied',\n",
       " 'occupied his',\n",
       " 'his immense',\n",
       " 'immense faculties',\n",
       " 'faculties and',\n",
       " 'and extraordinary',\n",
       " 'extraordinary powers',\n",
       " 'powers of',\n",
       " 'of observation',\n",
       " 'observation in',\n",
       " 'in following',\n",
       " 'following out',\n",
       " 'out those',\n",
       " 'those clues',\n",
       " 'clues and',\n",
       " 'and clearing',\n",
       " 'clearing up',\n",
       " 'up those',\n",
       " 'those mysteries',\n",
       " 'mysteries which',\n",
       " 'which had',\n",
       " 'had been',\n",
       " 'been abandoned',\n",
       " 'abandoned as',\n",
       " 'as hopeless',\n",
       " 'hopeless by',\n",
       " 'by the',\n",
       " 'the official',\n",
       " 'official police',\n",
       " 'police from',\n",
       " 'from time',\n",
       " 'time to',\n",
       " 'to time',\n",
       " 'time i',\n",
       " 'i heard',\n",
       " 'heard some',\n",
       " 'some vague',\n",
       " 'vague account',\n",
       " 'account of',\n",
       " 'of his',\n",
       " 'his doings',\n",
       " 'doings of',\n",
       " 'of his',\n",
       " 'his summons',\n",
       " 'summons to',\n",
       " 'to odessa',\n",
       " 'odessa in',\n",
       " 'in the',\n",
       " 'the case',\n",
       " 'case of',\n",
       " 'of the',\n",
       " 'the trepoff',\n",
       " 'trepoff murder',\n",
       " 'murder of',\n",
       " 'of his',\n",
       " 'his clearing',\n",
       " 'clearing up',\n",
       " 'up of',\n",
       " 'of the',\n",
       " 'the singular',\n",
       " 'singular tragedy',\n",
       " 'tragedy of',\n",
       " 'of the',\n",
       " 'the atkinson',\n",
       " 'atkinson brothers',\n",
       " 'brothers at',\n",
       " 'at trincomalee',\n",
       " 'trincomalee and',\n",
       " 'and finally',\n",
       " 'finally of',\n",
       " 'of the',\n",
       " 'the mission',\n",
       " 'mission which',\n",
       " 'which he',\n",
       " 'he had',\n",
       " 'had accomplished',\n",
       " 'accomplished so',\n",
       " 'so delicately',\n",
       " 'delicately and',\n",
       " 'and successfully',\n",
       " 'successfully for',\n",
       " 'for the',\n",
       " 'the reigning',\n",
       " 'reigning family',\n",
       " 'family of',\n",
       " 'of holland',\n",
       " 'holland beyond',\n",
       " 'beyond these',\n",
       " 'these signs',\n",
       " 'signs of',\n",
       " 'of his',\n",
       " 'his activity',\n",
       " 'activity however',\n",
       " 'however which',\n",
       " 'which i',\n",
       " 'i merely',\n",
       " 'merely shared',\n",
       " 'shared with',\n",
       " 'with all',\n",
       " 'all the',\n",
       " 'the readers',\n",
       " 'readers of',\n",
       " 'of the',\n",
       " 'the daily',\n",
       " 'daily press',\n",
       " 'press i',\n",
       " 'i knew',\n",
       " 'knew little',\n",
       " 'little of',\n",
       " 'of my',\n",
       " 'my former',\n",
       " 'former friend',\n",
       " 'friend and',\n",
       " 'and companion',\n",
       " 'companion one',\n",
       " 'one night',\n",
       " 'night it',\n",
       " 'it was',\n",
       " 'was on',\n",
       " 'on the',\n",
       " 'the twentieth',\n",
       " 'twentieth of',\n",
       " 'of march',\n",
       " 'march 1888',\n",
       " '1888 i',\n",
       " 'i was',\n",
       " 'was returning',\n",
       " 'returning from',\n",
       " 'from a',\n",
       " 'a journey',\n",
       " 'journey to',\n",
       " 'to a',\n",
       " 'a patient',\n",
       " 'patient for',\n",
       " 'for i',\n",
       " 'i had',\n",
       " 'had now',\n",
       " 'now returned',\n",
       " 'returned to',\n",
       " 'to civil',\n",
       " 'civil practice',\n",
       " 'practice when',\n",
       " 'when my',\n",
       " 'my way',\n",
       " 'way led',\n",
       " 'led me',\n",
       " 'me through',\n",
       " 'through baker',\n",
       " 'baker street',\n",
       " 'street as',\n",
       " 'as i',\n",
       " 'i passed',\n",
       " 'passed the',\n",
       " 'the well',\n",
       " 'well remembered',\n",
       " 'remembered door',\n",
       " 'door which',\n",
       " 'which must',\n",
       " 'must always',\n",
       " 'always be',\n",
       " 'be associated',\n",
       " 'associated in',\n",
       " 'in my',\n",
       " 'my mind',\n",
       " 'mind with',\n",
       " 'with my',\n",
       " 'my wooing',\n",
       " 'wooing and',\n",
       " 'and with',\n",
       " 'with the',\n",
       " 'the dark',\n",
       " 'dark incidents',\n",
       " 'incidents of',\n",
       " 'of the',\n",
       " 'the study',\n",
       " 'study in',\n",
       " 'in scarlet',\n",
       " 'scarlet i',\n",
       " 'i was',\n",
       " 'was seized',\n",
       " 'seized with',\n",
       " 'with a',\n",
       " 'a keen',\n",
       " 'keen desire',\n",
       " 'desire to',\n",
       " 'to see',\n",
       " 'see holmes',\n",
       " 'holmes again',\n",
       " 'again and',\n",
       " 'and to',\n",
       " 'to know',\n",
       " 'know how',\n",
       " 'how he',\n",
       " 'he was',\n",
       " 'was employing',\n",
       " 'employing his',\n",
       " 'his extraordinary',\n",
       " 'extraordinary powers',\n",
       " 'powers his',\n",
       " 'his rooms',\n",
       " 'rooms were',\n",
       " 'were brilliantly',\n",
       " 'brilliantly lit',\n",
       " 'lit and',\n",
       " 'and even',\n",
       " 'even as',\n",
       " 'as i',\n",
       " 'i looked',\n",
       " 'looked up',\n",
       " 'up i',\n",
       " 'i saw',\n",
       " 'saw his',\n",
       " 'his tall',\n",
       " 'tall spare',\n",
       " 'spare figure',\n",
       " 'figure pass',\n",
       " 'pass twice',\n",
       " 'twice in',\n",
       " 'in a',\n",
       " 'a dark',\n",
       " 'dark silhouette',\n",
       " 'silhouette against',\n",
       " 'against the',\n",
       " 'the blind',\n",
       " 'blind he',\n",
       " 'he was',\n",
       " 'was pacing',\n",
       " 'pacing the',\n",
       " 'the room',\n",
       " 'room swiftly',\n",
       " 'swiftly eagerly',\n",
       " 'eagerly with',\n",
       " 'with his',\n",
       " 'his head',\n",
       " 'head sunk',\n",
       " 'sunk upon',\n",
       " 'upon his',\n",
       " 'his chest',\n",
       " 'chest and',\n",
       " 'and his',\n",
       " 'his hands',\n",
       " 'hands clasped',\n",
       " 'clasped behind',\n",
       " 'behind him',\n",
       " 'him to',\n",
       " 'to me',\n",
       " 'me who',\n",
       " 'who knew',\n",
       " 'knew his',\n",
       " 'his every',\n",
       " 'every mood',\n",
       " 'mood and',\n",
       " 'and habit',\n",
       " 'habit his',\n",
       " 'his attitude',\n",
       " 'attitude and',\n",
       " 'and manner',\n",
       " 'manner told',\n",
       " 'told their',\n",
       " 'their own',\n",
       " 'own story',\n",
       " 'story he',\n",
       " 'he was',\n",
       " 'was at',\n",
       " 'at work',\n",
       " 'work again',\n",
       " 'again he',\n",
       " 'he had',\n",
       " 'had risen',\n",
       " 'risen out',\n",
       " 'out of',\n",
       " 'of his',\n",
       " 'his drug',\n",
       " 'drug created',\n",
       " 'created dreams',\n",
       " 'dreams and',\n",
       " 'and was',\n",
       " 'was hot',\n",
       " 'hot upon',\n",
       " 'upon the',\n",
       " 'the scent',\n",
       " 'scent of',\n",
       " 'of some',\n",
       " 'some new',\n",
       " 'new problem',\n",
       " 'problem i',\n",
       " 'i rang',\n",
       " 'rang the',\n",
       " 'the bell',\n",
       " 'bell and',\n",
       " 'and was',\n",
       " 'was shown',\n",
       " 'shown up',\n",
       " 'up to',\n",
       " 'to the',\n",
       " 'the chamber',\n",
       " 'chamber which',\n",
       " 'which had',\n",
       " 'had formerly',\n",
       " 'formerly been',\n",
       " 'been in',\n",
       " 'in part',\n",
       " 'part my',\n",
       " 'my own',\n",
       " 'own his',\n",
       " 'his manner',\n",
       " 'manner was',\n",
       " 'was not',\n",
       " 'not effusive',\n",
       " 'effusive it',\n",
       " 'it seldom',\n",
       " 'seldom was',\n",
       " 'was but',\n",
       " 'but he',\n",
       " 'he was',\n",
       " 'was glad',\n",
       " 'glad i',\n",
       " 'i think',\n",
       " 'think to',\n",
       " 'to see',\n",
       " 'see me',\n",
       " 'me with',\n",
       " 'with hardly',\n",
       " 'hardly a',\n",
       " 'a word',\n",
       " 'word spoken',\n",
       " 'spoken but',\n",
       " 'but with',\n",
       " 'with a',\n",
       " 'a kindly',\n",
       " 'kindly eye',\n",
       " 'eye he',\n",
       " 'he waved',\n",
       " 'waved me',\n",
       " 'me to',\n",
       " 'to an',\n",
       " 'an armchair',\n",
       " 'armchair threw',\n",
       " 'threw across',\n",
       " 'across his',\n",
       " 'his case',\n",
       " 'case of',\n",
       " 'of cigars',\n",
       " 'cigars and',\n",
       " 'and indicated',\n",
       " 'indicated a',\n",
       " 'a spirit',\n",
       " 'spirit case',\n",
       " 'case and',\n",
       " 'and a',\n",
       " 'a gasogene',\n",
       " 'gasogene in',\n",
       " 'in the',\n",
       " 'the corner',\n",
       " 'corner then',\n",
       " 'then he',\n",
       " 'he stood',\n",
       " 'stood before',\n",
       " 'before the',\n",
       " 'the fire',\n",
       " 'fire and',\n",
       " 'and looked',\n",
       " 'looked me',\n",
       " 'me over',\n",
       " 'over in',\n",
       " 'in his',\n",
       " 'his singular',\n",
       " 'singular introspective',\n",
       " 'introspective fashion',\n",
       " 'fashion wedlock',\n",
       " 'wedlock suits',\n",
       " 'suits you',\n",
       " 'you he',\n",
       " 'he remarked',\n",
       " 'remarked i',\n",
       " 'i think',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c9569",
   "metadata": {},
   "source": [
    "### Finding Occurences of the pair in corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102edacf",
   "metadata": {},
   "source": [
    "####  This process willtake lots of time so anoter aproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d2a51ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Total Pairs :  1115584\n",
      "Unique Pairs :  390694\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 300/390694 [00:09<3:25:25, 31.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     10\u001b[0m prob_dist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m tqdm(unique_pairs):\n\u001b[0;32m     13\u001b[0m     prob_dist\u001b[38;5;241m.\u001b[39mappend([pair, data\u001b[38;5;241m.\u001b[39mcount(pair)])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1188\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1186\u001b[0m dt \u001b[38;5;241m=\u001b[39m cur_t \u001b[38;5;241m-\u001b[39m last_print_t\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dt \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m mininterval \u001b[38;5;129;01mand\u001b[39;00m cur_t \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_start_t:\n\u001b[1;32m-> 1188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(n \u001b[38;5;241m-\u001b[39m last_print_n)\n\u001b[0;32m   1189\u001b[0m     last_print_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_print_n\n\u001b[0;32m   1190\u001b[0m     last_print_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_print_t\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1239\u001b[0m, in \u001b[0;36mtqdm.update\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ema_dn(dn)\n\u001b[0;32m   1238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ema_dt(dt)\n\u001b[1;32m-> 1239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh(lock_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock_args)\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_miniters:\n\u001b[0;32m   1241\u001b[0m     \u001b[38;5;66;03m# If no `miniters` was specified, adjust automatically to the\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m     \u001b[38;5;66;03m# maximum iteration rate seen so far between two prints.\u001b[39;00m\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;66;03m# e.g.: After running `tqdm.update(5)`, subsequent\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m     \u001b[38;5;66;03m# calls to `tqdm.update()` will only cause an update after\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m     \u001b[38;5;66;03m# at least 5 more iterations.\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxinterval \u001b[38;5;129;01mand\u001b[39;00m dt \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxinterval:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1344\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[1;34m(self, nolock, lock_args)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1343\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m-> 1344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay()\n\u001b[0;32m   1345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[0;32m   1346\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1492\u001b[0m, in \u001b[0;36mtqdm.display\u001b[1;34m(self, msg, pos)\u001b[0m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[0;32m   1491\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(pos)\n\u001b[1;32m-> 1492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__str__\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m msg)\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[0;32m   1494\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(\u001b[38;5;241m-\u001b[39mpos)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:347\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.print_status\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_status\u001b[39m(s):\n\u001b[0;32m    346\u001b[0m     len_s \u001b[38;5;241m=\u001b[39m disp_len(s)\n\u001b[1;32m--> 347\u001b[0m     fp_write(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m s \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmax\u001b[39m(last_len[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m len_s, \u001b[38;5;241m0\u001b[39m)))\n\u001b[0;32m    348\u001b[0m     last_len[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m len_s\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:340\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.fp_write\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfp_write\u001b[39m(s):\n\u001b[1;32m--> 340\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(s))\n\u001b[0;32m    341\u001b[0m     fp_flush()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\utils.py:127\u001b[0m, in \u001b[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py:648\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 648\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule_flush()\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py:545\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_schedule_in_thread\u001b[39m():\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39mcall_later(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_interval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[1;32m--> 545\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(_schedule_in_thread)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py:251\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_pipe\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     f()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\zmq\\sugar\\socket.py:618\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    611\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[0;32m    612\u001b[0m             data,\n\u001b[0;32m    613\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[0;32m    614\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    615\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[0;32m    616\u001b[0m         )\n\u001b[0;32m    617\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m--> 618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msend(data, flags\u001b[38;5;241m=\u001b[39mflags, copy\u001b[38;5;241m=\u001b[39mcopy, track\u001b[38;5;241m=\u001b[39mtrack)\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:740\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:787\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:244\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('-'*30)\n",
    "\n",
    "print('Total Pairs : ', len(data))\n",
    "unique_pairs = list(set(data))\n",
    "\n",
    "print('Unique Pairs : ', len(unique_pairs))\n",
    "\n",
    "print('-'*30)\n",
    "\n",
    "prob_dist = []\n",
    "\n",
    "for pair in tqdm(unique_pairs):\n",
    "    prob_dist.append([pair, data.count(pair)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b31b0",
   "metadata": {},
   "source": [
    "### Another Aproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "436e6836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Total Pairs :  1115584\n",
      "Unique Pairs :  390694\n",
      "------------------------------\n",
      "390694\n"
     ]
    }
   ],
   "source": [
    "a = np.array(data)\n",
    "\n",
    "pair , count = np.unique(a, return_counts = True)\n",
    "\n",
    "print('-'*30)\n",
    "print('Total Pairs : ' , len(data))\n",
    "unique_pairs = list(set(data))\n",
    "print('Unique Pairs : ', len(pair))\n",
    "print('-'*30)\n",
    "\n",
    "\n",
    "prob_dist = []\n",
    "for i in range(len(pair)):\n",
    "    prob_dist.append([pair[i] ,count[i] , pair[i].split(' ')[-1]])\n",
    "    \n",
    "print(len(prob_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a307ddb",
   "metadata": {},
   "source": [
    "### Predicting the next mostly probable word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c068e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(prob_dist, columns = ['pair','freq','out'])\n",
    "df = df[df['freq'] >= 5]\n",
    "df.head()\n",
    "\n",
    "\n",
    "def predict(word):\n",
    "    \n",
    "    df_pred = []\n",
    "    for i in df.values:\n",
    "        if i[0].split(' ')[0] == word:\n",
    "            df_pred.append([i[0], i[1], i[2]])\n",
    "\n",
    "    df_pred = pd.DataFrame(df_pred, columns = ['in','freq','out'])\n",
    "    return list(df_pred.sort_values(by = 'freq', ascending = False).head()['out'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abeb635",
   "metadata": {},
   "source": [
    "#### Predicting the next word for one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3a535c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['same', 'french', 'first', 'old', 'emperor']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792cb473",
   "metadata": {},
   "source": [
    "#### Predicting the next Sequnces of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b56ab438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of the same time to the same time to the same time to the same time to the same time "
     ]
    }
   ],
   "source": [
    "word = 'one'\n",
    "\n",
    "for i in range(20):\n",
    "\n",
    "    pred = predict(word)\n",
    "    word = pred[0]\n",
    "    \n",
    "    print(word, end = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb0ab7f",
   "metadata": {},
   "source": [
    "#### Predicting the Sequnces Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "216e556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'was', 'way', 'and', 'time']\n",
      "Enter the Index : 0\n",
      "['a', 'the', 'not', 'to', 'it']\n",
      "Enter the Index : 2\n",
      "['to', 'be', 'only', 'know', 'a']\n",
      "Enter the Index : 3\n",
      "['that', 'what', 'how', 'i', 'the']\n",
      "Enter the Index : 3\n",
      "['have', 'am', 'was', 'don', 'had']\n",
      "Enter the Index : 2\n",
      "--------------------\n",
      "this is not know i was\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "word = 'this'\n",
    "\n",
    "preds = []\n",
    "preds.append(word)\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    pred = predict(word)\n",
    "    print(pred)\n",
    "    word = pred[int(input('Enter the Index : '))]\n",
    "    preds.append(word)\n",
    "    \n",
    "print('-'*20)\n",
    "print(' '.join(preds))\n",
    "print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c663281a",
   "metadata": {},
   "source": [
    "### Finding n pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce2be8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(words, n):\n",
    "    \n",
    "    n = n+1  \n",
    "    data = []\n",
    "    for i in range(len(words) - n):\n",
    "        data.append(' '.join(words[i:i+n]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2337a515",
   "metadata": {},
   "source": [
    "### Finding the Probablity on the n pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ac00f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_dist(data):\n",
    "    \n",
    "    a = np.array(data)\n",
    "\n",
    "    pair , count = np.unique(a, return_counts = True)\n",
    "    unique_pairs = list(set(data))\n",
    "\n",
    "    prob_dist = []\n",
    "\n",
    "    for i in range(len(unique_pairs)):\n",
    "        prob_dist.append([unique_pairs[i] , ' '.join(unique_pairs[i].split(' ')[:-1]), unique_pairs[i].split(' ')[-1], count[i]])\n",
    "\n",
    "    return prob_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e36827e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_pairs(words,4)\n",
    "prob_dist = get_prob_dist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82560cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089074"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prob_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c404a",
   "metadata": {},
   "source": [
    "### Predicting the next n Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68af5d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['country'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(prob_dist, columns = ['seq','inp','out','freq'])\n",
    "df.head()\n",
    "\n",
    "\n",
    "def predict(word):\n",
    "\n",
    "    if len(df[df['inp'] == word]):\n",
    "        df_ = df[df['inp'] == word]\n",
    "        return df_.sort_values(by = 'freq').head()['out'].values\n",
    "    else:\n",
    "        print('Seq is not present')\n",
    "        \n",
    "predict('this is a beautiful')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce591b",
   "metadata": {},
   "source": [
    "#### Prediction for one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8027bb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq is not present\n"
     ]
    }
   ],
   "source": [
    "predict('the is a beautiful')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d1d1c",
   "metadata": {},
   "source": [
    "### Predicting by auto screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "092cc5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of the united states huerta was doomed in the summer of 1900 is to seek a solution which may bring about permanent safety and peace to china preserve chinese territorial and administrative entity protect all rights guaranteed to friendly powers by treaty and international law and safeguard for the world the principle of equal'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pred_seq(seq,n):\n",
    "\n",
    "    output = []\n",
    "    output.append(seq)\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        pred = predict(seq)\n",
    "        seq = ' '.join(seq.split(' ')[1:]) + ' ' + pred[0]\n",
    "        output.append(pred[0])\n",
    "        \n",
    "    return ' '.join(output)\n",
    "    \n",
    "pred_seq('of the united states', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f9d379",
   "metadata": {},
   "source": [
    "#### Getting the pairs of n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9eb711da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(words, n):\n",
    "    \n",
    "    data = []\n",
    "    for i in range(len(words) - n):\n",
    "        data.append(' '.join(words[i:i+n]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69672b6a",
   "metadata": {},
   "source": [
    "#### Getting the probablity Distribution of n - grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb0e100e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>left_seq</th>\n",
       "      <th>right_seq</th>\n",
       "      <th>output</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 05 grm</td>\n",
       "      <td>0</td>\n",
       "      <td>grm</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 25 u</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 45 grm</td>\n",
       "      <td>0</td>\n",
       "      <td>grm</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 5 to</td>\n",
       "      <td>0</td>\n",
       "      <td>to</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 6 grm</td>\n",
       "      <td>0</td>\n",
       "      <td>grm</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        seq left_seq right_seq output  freq\n",
       "0  0 05 grm        0       grm     05     1\n",
       "1    0 25 u        0         u     25     1\n",
       "2  0 45 grm        0       grm     45     1\n",
       "3    0 5 to        0        to      5     1\n",
       "4   0 6 grm        0       grm      6     4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prob_dist(data):\n",
    "    \n",
    "    prob_dist = []    \n",
    "    a = np.array(data)\n",
    "    pairs, counts = np.unique(a, return_counts = True)\n",
    "    \n",
    "    for i in range(len(pairs)):\n",
    "        \n",
    "        left_seq   = ' '.join(pairs[i].split(' ')[:len(pairs[i].split(' '))//2])\n",
    "        right_seq  = ' '.join(pairs[i].split(' ')[len(pairs[i].split(' '))//2 + 1: ])\n",
    "        middle_seq = pairs[i].split(' ')[len(pairs[i].split(' '))//2]\n",
    "        \n",
    "        prob_dist.append([pairs[i],left_seq, right_seq, middle_seq, counts[i]])\n",
    "        \n",
    "    return prob_dist\n",
    "        \n",
    "    \n",
    "data = get_pairs(words,3)\n",
    "prob_dist = get_prob_dist(data)\n",
    "\n",
    "df = pd.DataFrame(prob_dist, columns = ['seq','left_seq','right_seq','output','freq'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c496194",
   "metadata": {},
   "source": [
    "#### Getting the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "587f6091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['united', 'several', 'southern', 'northern', 'planting']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(word):\n",
    "    \n",
    "    left_seq  = word.split('_')[0].strip()\n",
    "    right_seq = word.split('_')[1].strip()\n",
    "\n",
    "    df_ = df[df['left_seq'] == left_seq]\n",
    "    df_ = df_[df_['right_seq'] == right_seq]\n",
    "\n",
    "    return list(df_.sort_values(by = 'freq', ascending = False).head()['output'].values)\n",
    "\n",
    "\n",
    "predict('the _ states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a2074ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>left_seq</th>\n",
       "      <th>right_seq</th>\n",
       "      <th>output</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 05 grm</td>\n",
       "      <td>0</td>\n",
       "      <td>grm</td>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532804</th>\n",
       "      <td>ponderous maketh repaid</td>\n",
       "      <td>ponderous</td>\n",
       "      <td>repaid</td>\n",
       "      <td>maketh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532805</th>\n",
       "      <td>ponderous steps up</td>\n",
       "      <td>ponderous</td>\n",
       "      <td>up</td>\n",
       "      <td>steps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532806</th>\n",
       "      <td>pondicherry in a</td>\n",
       "      <td>pondicherry</td>\n",
       "      <td>a</td>\n",
       "      <td>in</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532807</th>\n",
       "      <td>pondicherry in january</td>\n",
       "      <td>pondicherry</td>\n",
       "      <td>january</td>\n",
       "      <td>in</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300214</th>\n",
       "      <td>he did not</td>\n",
       "      <td>he</td>\n",
       "      <td>not</td>\n",
       "      <td>did</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485191</th>\n",
       "      <td>of the united</td>\n",
       "      <td>of</td>\n",
       "      <td>united</td>\n",
       "      <td>the</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511323</th>\n",
       "      <td>out of the</td>\n",
       "      <td>out</td>\n",
       "      <td>the</td>\n",
       "      <td>of</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699401</th>\n",
       "      <td>the united states</td>\n",
       "      <td>the</td>\n",
       "      <td>states</td>\n",
       "      <td>united</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497287</th>\n",
       "      <td>one of the</td>\n",
       "      <td>one</td>\n",
       "      <td>the</td>\n",
       "      <td>of</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>829931 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            seq     left_seq right_seq  output  freq\n",
       "0                      0 05 grm            0       grm      05     1\n",
       "532804  ponderous maketh repaid    ponderous    repaid  maketh     1\n",
       "532805       ponderous steps up    ponderous        up   steps     1\n",
       "532806         pondicherry in a  pondicherry         a      in     1\n",
       "532807   pondicherry in january  pondicherry   january      in     1\n",
       "...                         ...          ...       ...     ...   ...\n",
       "300214               he did not           he       not     did   239\n",
       "485191            of the united           of    united     the   242\n",
       "511323               out of the          out       the      of   253\n",
       "699401        the united states          the    states  united   380\n",
       "497287               one of the          one       the      of   380\n",
       "\n",
       "[829931 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = 'freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf2800d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
